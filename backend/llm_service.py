import json
import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
from models import PresentationData

# load .env variables
load_dotenv()

# initialize client
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- prompt engineering åœ¨è¿™é‡Œå†™æ ¸å¿ƒé€»è¾‘ ---
async def generate_ppt_content(topic: str) -> PresentationData:
    print(f"ğŸ§  [LLM] æ­£åœ¨ä¸º '{topic}' æ„æ€å¤§çº²...")
    
    # è¿™æ˜¯ä¸€ä¸ª Mock (æ¨¡æ‹Ÿ) å‡½æ•°ï¼Œæš‚æ—¶ä¸æ¶ˆè€— Token
    # æ¨¡æ‹Ÿä»æœ¬åœ°æ–‡ä»¶è¯»å–æ•°æ®ï¼Œæ–¹ä¾¿æµ‹è¯•æ¸²æŸ“å¼•æ“
    try:
        # 1. ç¡®å®šæ–‡ä»¶è·¯å¾„
        # å‡è®¾ llm_service.py å’Œ mock_data.json éƒ½åœ¨ backend ç›®å½•ä¸‹
        # os.path.dirname(__file__) è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        json_path = os.path.join(current_dir, "mock_data.json")

        # 2. è¯»å–æ–‡ä»¶
        with open(json_path, "r", encoding="utf-8") as f:
            data_dict = json.load(f)

        # 3. è½¬æ¢ä¸º Pydantic å¯¹è±¡ (è¿™ä¸€æ­¥ä¼šè¿›è¡Œæ•°æ®æ ¡éªŒ)
        presentation = PresentationData(**data_dict)
        
        # 4. (å¯é€‰) å¦‚æœä½ æƒ³å‡è£…æ˜¯æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆçš„ï¼Œå¯ä»¥æŠŠ topic è¦†ç›–æ‰
        # presentation.topic = topic 
        
        return presentation

    except FileNotFoundError:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° backend/mock_data.json æ–‡ä»¶ï¼")
        return PresentationData(topic="Error", slides=[])
    except json.JSONDecodeError:
        print("âŒ é”™è¯¯ï¼šJSON æ ¼å¼ä¸å¯¹ï¼è¯·æ£€æŸ¥é€—å·å’Œå¼•å·ã€‚")
        return PresentationData(topic="Error", slides=[])
    except Exception as e:
        print(f"âŒ æ•°æ®æ ¡éªŒå¤±è´¥: {e}")
        return PresentationData(topic="Error", slides=[])
    
    # verify data format matches Pydantic definition
    # return PresentationData(**mock_json)